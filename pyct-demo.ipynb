{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYCT: CrowdTangle data retrieval in Python\n",
    "\n",
    "Full API documentation at [github.com/CrowdTangle/API/wiki](https://github.com/CrowdTangle/API/wiki)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### `pyct.auth()`\n",
    "\n",
    "Connect to one of your dashboards through its API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyct.auth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### `pyct.lists()`\n",
    "\n",
    "See which lists you have in the dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyct.lists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### `pyct.getlists()`\n",
    "\n",
    "This gets data from all \"Lists\" in the current CT dashboard. \n",
    "\n",
    "- Get 100 posts per call.\n",
    "- Set a pause of, at least, 10 seconds between calls to avoid hitting the rate limit (6 calls per minute).\n",
    "- Gets data from all Lists within the current dashboard, but not from any Saved Searches.\n",
    "- Saves data iteratively to a growing csv while paging through results.\n",
    "- Will get a maximum of 10k posts for the given slice of time. Set start/and or end dates manually to fit for slices that fall below 10k results, in order to get all data.\n",
    "- If you have lots of data for every day, note that `startdate` and `enddate` can be set down to the second using this format `2018-12-28T07:23:05`\n",
    "- If you get no output, try a different daterange.\n",
    "\n",
    "Format:\n",
    "`pyct.lists(startdate,enddate,pause)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyct.getlists('2019-01-01T07:00:01', '2019-01-01T07:00:02',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### `pyct.getsearch`\n",
    "\n",
    "This gets data from \"Saved Searches\" in the current CT dashboard. \n",
    "\n",
    "- Gets 100 posts per call.\n",
    "- Set a pause of, at least, 10 seconds between calls to avoid hitting the rate limit (6 calls per minute).\n",
    "- Gets data from the Saved Searches that you specify through its id number. The `id` parameter should be formatted like this `'1421573'` when calling for only one search list, and comma separated --`'1421573,1426545'` when you want two or more.\n",
    "- Saves data iteratively to csv while paging through results.\n",
    "- Will get a maximum of 10k posts for a set slice of time. Set start/and or end dates manually to fit for slices that fall below 10k results.\n",
    "- If you have lots of data for every day, note that `startdate` and `enddate` can be set down to the second using this format `2018-12-28T07:23:05`\n",
    "- If you get no output, try a different daterange.\n",
    "\n",
    "Format:\n",
    "`pyct.getsearch(id,startdate,enddate,pause)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect id numbers of your Saved Searches and use one of your SAVED_SEARCH ids below\n",
    "pyct.lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyct.getsearch('1426545,1444036','2020-07-30','2020-10-15',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### `pyct.getlistsfast()`\n",
    "\n",
    "This function for getting data from all \"Lists\" is for users that have been allowed by CT to get more than 100 posts per call. The function is written for a use case where we assume the limit to be at 10,000 posts.\n",
    "\n",
    "The function gets data from all \"Lists\" in the current CT dashboard\n",
    "\n",
    "- Gets 10,000 posts per call.\n",
    "- Gets data from all Lists within the current dashboard, but not from any Saved Searches.\n",
    "- Does not use the paging method to advance through results, but instead uses a method where the end date of a previous query becomes the starting point for the following query.\n",
    "- Set a pause of, at least, 10 seconds between calls to avoid hitting the rate limit (6 calls per minute).\n",
    "- Saves data iteratively to csv while retrieving new results.\n",
    "- Will get a maximum of 60k posts per minute. \n",
    "\n",
    "Format:\n",
    "`pyct.getlistsfast(pause)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyct.getlistsfast(15) # got 70k with 10 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### `pyct.search()`\n",
    "Users that have been provided access by CT to the `GET /posts/search` endpoint can use this method for getting data. Access is granted based on the use case and on a dashboard-by-dashboard basis. You only have access if you are using an API token that comes from a dashboard with the search API activated.\n",
    "\n",
    "This function will retrieve posts from both pages, groups and profiles, for a set of given parameters and search terms. \n",
    "\n",
    "Note that this endpoint, unlike the `GET /posts endpoint`, searches the entire, cross-platform CrowdTangle system of posts. It can be limited by lists and accounts, but by default will search beyond the dashboard that the token is associated with. This means that if you are using the `GET /posts/search` endpoint, it doesn't really matter what lists you have added to your dashboard.\n",
    "\n",
    "Searches can be customised in different ways, described in the [API documentation](https://github.com/CrowdTangle/API/wiki/Search).\n",
    "\n",
    "This `pyct` function will save each batch of retrieved data as a separate csv file.\n",
    "\n",
    "Format:\n",
    "`pyct.search(count,startdate,enddate,sort_by,pause,searchterms)`\n",
    "\n",
    "- Set `count` at 100, or at your allowed number.\n",
    "- Set `startdate` and `enddate` for the search.\n",
    "- Set the sorting method to one out of: 'date', '[interaction_rate](https://help.crowdtangle.com/en/articles/1141064-how-is-interaction-rate-calculated)', 'total_interactions', '[overperforming](https://help.crowdtangle.com/en/articles/1141056-how-is-overperforming-calculated)', or 'underperforming'.\n",
    "- Set a `pause` of, at least, 10 seconds between calls to avoid hitting the rate limit (6 calls per minute).\n",
    "- Set the `searchterms`. Format: 'data, datascience, data science'. The comma-separated terms will be joined by the OR operator. See [API documentation](https://github.com/CrowdTangle/API/wiki/Search) on how to deal with AND-searches, and other customisations. Also the comma-separated terms are seen as phrases, so that \"data, data science\", will search for posts either matching \"data\" or \"data science\", but not \"science\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyct.search(10000,'2020-09-30', '2020-10-02','date',10,'covid,corona,trump')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### `pyct.joinsearchcsvs()`\n",
    "\n",
    "As data gathered through the `pyct.search()` function will output several csvs, the function below offers an automated method for joining them together. \n",
    "\n",
    "The function takes all csvs in your '_data' directory that have been produced using `pyct.search()`, meaning that their filenames start with 'pyct-data-search-*'. Make sure that only such files that you want to merge are present in the directory.\n",
    "\n",
    "Note that the function will not delete the individual csvs, but create an additional merged version of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyct.joinsearchcsvs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
